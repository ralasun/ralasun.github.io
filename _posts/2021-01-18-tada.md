---
layout : post
title: TADA, Trend Alignment with Dual-Attention Multi-Task Recurrent Neural Networks for Sales Prediction 논문 리뷰
category: Deep Learning
tags: time-series-analysis
---

*** 

다변량 시계열 예측 모델에 관한 논문으로, 다변량 시계열 데이터를 가지고 encoder-decoder RNN 모델 기반으로 dual-attention과 multi-task RNN으로 구성된 모델입니다. 

***

<h2>Problem</h2>
다변량 시계열 예측을 위한 여러 통계 기반 모델링이 있으나, 판매량에 영향을 주는 변수들 간의 관계를 파악하기 어렵고, 이 변수들로 부터 의미있는 정보(contextual information)을 추출하는 건 더욱 어렵습니다. 예를 들어, 겨울의복은 날씨에 영향에 두드러지게 받지만, 일반적인 셔츠는 사계절내내 잘 입는 옷이기 때문에 겨울의복보단 계절의 영향을 덜 받습니다. 또한 소비자의 주관적인 선호도(브랜드 선호도, 상품 선호도 등)에 따라 상품 판매는 크게 또한 달라지게 됩니다. 따라서, 본 논문에서 주목하는 다변량 시계열 예측에서의 문제는 아래와 같이 크게 세가지입니다.

<ol><li>how to fully capture the dynamic dependencies among multiple influential factors?<br>
판매에 영향을 주는 여러 변수들 간의 관계는 시간에 따라 변할 가능성이 높습니다. 그렇다면 매 스텝마다 변수들 간의 관계를 어떻게 포착할 수 있을까요 ?</li><li>how can we possibly glean wisdoms form the past to compensate for the unpredictability of influential factors?<br>이 변수들이 미래에 어떻게 변할지는 아무도 모릅니다. 그렇다면 과거 이 변수들의 정보만을 가지고 어떻게 미래를 눈여겨 볼 수 있는 정보를 추출할지는 생각해 봐야 합니다.</li>
<li>how to align the upcoming trend with historical sales trends?<br>현실 시계에서의 판매 트랜드는 전혀 규칙적이지 않습니다. 그렇다면 과거 판매 트렌드를 어떻게 하면 현실 트렌드와 연관지을 수 있을까요 ?</li></ol>

<h2>TADA : Trend Alignment with Dual-Attention Multi-Task RNN</h2>

<h3>Problem Formulation</h3>

본 논문에서 풀고자 하는 다변량 시계열 예측 문제는 아래와 같이 수학적으로 정의됩니다.

$$\{\hat{y_t\}}^{T+\triangle}_{t=T+1} = F({\{\mathbf x_t\}}^{T}_{t=1}, {\{y_t\}}^{T}_{t=1})$$

$\mathbf x_t$ 는 influential factors로 판매량 이외의 변수(ex. 날씨, 브랜드, 상품인덱스 등)이고, $y_t$ 는 판매량 입니다. 

<h3>TADA 모델 개요</h3>
<p align='center'><img src='https://imgur.com/w09ZSHF.png'><figcaption align='center'>그림 1. 모델 개요</figcaption></p>

위의 그림은 본 논문의 모델 개요입니다. 크게 아래와 같이 구성되어 있습니다.
- Multi-task based Encoder Structures
- Dual-Attention based Decoder Structures
	- Attention got weighted decoder input mapping
	- attention for trend alignment

<h4>Multi-task based Encoder Structures</h4>
<p align='center'><img src='https://imgur.com/leH0yfV.png'><figcaption align='center'>그림 2. Multi-task based Encoder</figcaption></p>

influential factor의 semantic한 특징을 잘 추출한다면 분명 예측에 도움이 될 것입니다. 그러나 매 타임 스텝마다 어떻게 하면 판매량 예측에 도움될 semantic한 특징을 추출할 수 있을까요 ? 본 논문에서는 influential factor를 크게 intrinsic한 속성과 objective한 속성으로 나누어 LSTM을 이용한 인코딩을 각각 따로하였습니다. 이를 통해 각각 두 개의 LSTM(intrinsic LSTM, external LSTM)을 통해 각기 다른 semantic한 특징을 추출할 수 있습니다. 따라서, 위의 문제 정의는 아래와 같이 다시 정의될 수 있습니다. 

$$\{\hat{y_t\}}^{T+\triangle}_{t=T+1} = F({\{\mathbf x_t^{int}\}}^{T}_{t=1}, {\{\mathbf x_t^{ext}\}}^{T}_{t=1}, {\{y_t\}}^{T}_{t=1})$$

intrinsic한 속성이란 브랜드, 카테고리, 가격등 상품과 관련된 것이고, objective한 속성은 날씨, 휴일유무, 할인등과 관련된 속성입니다. 아래 표는 논문에서 실험한 데이터의 intrinsic/objective 속성입니다.

하지만 우리가 구하고 싶은 건 두 가지의 다른 semantic한 feature를 적절하게 결합하여 의미있는 **contextual vector**를 만드는 것입니다. 따라서 또다른 LSTM 네트워크인 Synergic LSTM을 구축하여 joint representation을 학습합니다. 이때, Synergic LSTM에 입력으로 들어가는 건 각 타임스텝에 해당되는 $h_t^{int}$ 와 $h_t^{ext}$ 뿐만 아니라 판매량 $y_t$ 도 같이 joint space가 구축되도록 학습됩니다. 

먼저, 두 타입스텝 t에서의 두 개의 hidden state을 $h_t^{int}$ 와 $h_t^{ext}$ 이용하여 Synergic LSTM의 인풋인 $\mathbf X_t^{syn}$ 을 아래와 같이 계산합니다.

$$\mathbf X_t^{syn} = \mathbf W_{syn}[\mathbf h_t^{int};\mathbf h_t^{ext};y_t]$$

그런 다음, intrinsic LSTM/external LSTM과 동일하게 각 타임스텝마다 두 정보가 결합되어 인코딩된 hidden stated인 $\mathbf h^{con}_t$ 를 계산합니다.

<p align='center'><img src='https://imgur.com/ijwajF4.png'><figcaption align='center'>그림 3. Multi-task based Encoder(2)</figcaption></p>

<h4>Dual-Attention based Decoder Structures</h4>
Multi-task Encoder를 통해 과거 판매량 시계열 데이터를 인코딩하면 contextual vectors인 ${\mathbf h_t^{con}}^T_{t=1}$ 이 계산되어 나옵니다. $h_t^{con}$ 은 타임스텝 t까지의 시계열 데이터에 대한 contextual 정보를 품고 있습니다.

LSTM decoder도 encoder와 유사하게 예측에 필요한 contextual vector $\mathbf d_t^{con}$ 을 생성합니다. 따라서, $T < t \leq T + \Delta$ 에 대해 decoder 수학식은 아래와 같습니다.

$$\mathbf d_t^{con} = LSTM^{dec}(\mathbf x_t^{dec}, \mathbf d^{con}_{t-1})$$

위 식에서 $\mathbf x_t^{dec}$ 는 attention weighted input입니다. 그러면 contextual vector가 어떻게 만들어지는지 보기 전에 attention weighted input 계산 과정을 살펴봅시다.

<h5>Attention for Weighted Decoder Input Mapping</h5>

<p align='center'><img src='https://imgur.com/NvCkYMs.png'><figcaption align='center'>그림 4. Attention for Weighted Decoder Input</figcaption></p>

Decoder에 입력될 Input은 encoder contextual vector들에서 각 디코터 타임 스텝에 필요한 정보를 적절하게 취하도록 하기 위해 attention 메카니즘을 통해 생성합니다.

$$\mathbf x_t^{dec} = \mathbf W_{dec}\left[\sum_{t'=1}^T \alpha_{tt'}^{int}\mathbf h_{t'}^{int};\sum_{t'=1}^T \alpha_{tt'}^{ext}\mathbf h_{t'}^{ext}\right] + \mathbf b_{dec}$$

$\alpha_{tt'}^{int}$ 와 $\alpha_{tt'}^{ext}$ 는 어텐션 가중치를 의미합니다. 어텐션 가중치는 아래 과정을 통해 계산됩니다.

$$e^{int}_{tt'} = \mathbf v^{\mathrm T}_{int}tanh(\mathbf M_{int}\mathbf d_{t-1}^{con} + \mathbf H_{int}\mathbf h_{t'}^{int})$$

$$e^{ext}_{tt'} = \mathbf v^{\mathrm T}_{ext}tanh(\mathbf M_{int}\mathbf d_{t-1}^{con} + \mathbf H_{ext}\mathbf h_{t'}^{ext})$$

$$\alpha_{tt'}^{int} = \frac{exp(e_{tt'}^{int})}{\sum_{s=1}^{T}exp(e_{ts}^{int})}$$

$$\alpha_{tt'}^{ext} = \frac{exp(e_{tt'}^{ext})}{\sum_{s=1}^{T}exp(e_{ts}^{ext})}$$

이때, $\sum_{t'=1}^{T}\alpha_{tt'}^{int} = \sum_{t'=1}^{T}\alpha_{tt'}^{ext} = 1$ 이 여야 합니다. 

<h5>Attention for Trend Alignment</h5>

<p align='center'><img src='https://imgur.com/riUczJ9.png'><figcaption align='center'>그림 5. Attention for Trend Alignment</figcaption></p>

미래를 예측하기 위해선 과거의 trend 패턴을 안다면 좀 더 수월할 수 있습니다. 따라서, 미래에 예상되는 패턴과 유사한 패턴을 과거에서 찾는 작업을 attention을 통해 진행하는 과정을 본 논문에서 제안하였습니다. 그러나, 
일반적으로 attention 메카니즘은 현 타임스텝에서 아웃풋을 출력하기 위해 이전 hidden state들중에서 가장 align되는 정보를 선택합니다. 과거 정보들 중에서 **미래의 트렌드와 유사한 트렌드 정보**를 선택적으로 이용하고 싶다면 전통적인 attention 메카니즘을 그대로 사용하기는 어렵습니다. 왜냐하면, 일반적인 데이터에선 trend외에 노이즈도 많이 포함하고 있기 때문입니다. 즉, 전체 데이터에 trend + noise라서 이전 모든 과거들에서 유사한 trend 패턴만을 집중하는 건 힘듭니다. 따라서 논문 저자는 아래와 같은 방법을 고안하였습니다.

먼저, ${\mathbf h_t^{con}}_{t=1}^T$ 를 $\triangle$ 타임 스텝 크기에 해당되는  contextual vector를 이어붙여서 $\triangle$ -step trend vector를 생성합니다. 

<p align='center'><img src='https://imgur.com/yUmHRP0.png'></p>

$\mathbf p_i$ 는 과거 시계열 데이터에서 $\triangle$ 간격에 해당되는 구간의 트렌드를 나타냅니다. $i$ 가 1씩 증가하므로, 마치 슬라이딩 윈도우 1씩 움직이면서 트렌드를 포착하는 것과 유사합니다. 

마찬가지 방식으로 decoder hidden state들을 이어 붙여 미래에 예상될 트렌드 정보를 생성합니다. 

<p align='center'><img src='https://imgur.com/I9C1wnQ.png'></p>

따라서, 그림5 처럼 과거에 생성된 트렌드 벡터과 미래 트렌드 벡터를 각각 내적하여 가장 큰 값에 해당되는 인덱스 i를 반환합니다. 내적값이 가장 크다는 것은 가장 유사함을 의미합니다.

$$e_i^{trd} = \mathbf p_i^{\mathrm T} \tilde{\mathbf p}$$

$$i' = argmax(e_i^{trd} , e_{i+1}^{trd},\dots, e_{T+\triangle -1}^{trd})$$

그 다음 $\mathbf p_{i'}$ 내의 각 ${\mathbf d_t^{con}}$ 와 $\mathbf h_t^{con}$ 을 아래와 같은 계산과정을 거쳐서 $\tilde {\mathbf d}^{con}$ 을 생성합니다.

<p align='center'><img src='https://imgur.com/haL8Udd.png'></p>

$\tilde {\mathbf d}^{con}$ 은 타임스텝 t에서의 과거 유사한 트렌드 정보에 집중하여 생성된 aligned contextual vector 입니다.

<h4>Sales Prediction and Model Learning</h4>

위에서 생성된 aligned contextual vector ${\widetilde {\mathbf d_t}^{con}}$ 를 가지고 판매량을 예측합니다.

$$\hat y_t = \mathbf v_y^{\mathrm T} \mathbf {\widetilde d}^{con} + b_y$$

$\hat y_t , \,\,(T+1 \leq t \leq T+\Delta)$ 는 타임스텝 T에서의 예측된 판매량입니다. 

본 논문에서 학습은 L2 regularization과 함께 Mean Squared Error를 minimize하였습니다.

<h2>Experiment and result.</h2>

전체적인 결과에 관한 건 논문을 참고 바랍니다. trend alignment 부분에 대한 결과를 살펴보면 과거 유사하다고 찾은 trend와 예측된 trend는 아래 그래프와 같이 나왔습니다. 

<p align='center'><img src='https://imgur.com/F5w1W2o.png'></p>
보면 어느정도 과거 매치된 트렌드와 유사한 트렌드를 따르는 것을 확인할 수 있었습니다.

<h2>Lessons Learned</h2>
 - 결과를 보면 어느정도 lag가 발생하는 것으로 보입니다. 
 - trend에 대한 파악을 먼저하고 판매량 데이터 입력을 나중에 하면 어떨까?
 - dual-stage attention에서의 input attention 모듈과 multi-tasked encoder를 결합하는 건 어떨까 ??

***

이상으로 본 논문 리뷰를 마치겠습니다. 

***
1.  Chen, Tong, et al. "Tada: trend alignment with dual-attention multi-task recurrent neural networks for sales prediction." 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 2018.
