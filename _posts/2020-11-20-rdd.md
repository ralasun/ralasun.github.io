---
layout : post
title: 2. RDD, Resilient Distributed DataSet에 대하여
category: Spark Programming
tags: data-engineering, spark
---

이번 포스팅은 "빅데이터 분석을 위한 스파크2 프로그래밍 - Chaper2. RDD" 를 읽고 정리하였습니다. 정리 순서는 책 순서와 동일하고, 책을 읽어가면서 이해가 안되는 부분을 추가적으로 정리하였습니다.

<h2>2.1 RDD</h2>
<h3>2.1.1 들어가기에 앞서</h3>

RDD를 공부하기 전 기억하고 넘어가야 할 것들에 대해 정리하였습니다.
<h4>스파크 클러스터</h4>
클러스터란 여러 대의 서버가 마치 한대의 서버처럼 동작하는 것을 뜻합니다. 스파크는 클러스터 환경에서 동작하며 대량의 데이터를 여러 서버에서 병렬 처리합니다

<h4>분산 데이터로서의 RDD</h4>
RDD는 Resilient Distrubuted Datasets으로, '회복력을 가진 분산 데이터 집합'이란 뜻입니다. (Resilient : 회복력이 있는) 데이터를 처리하는 과정에서 문제가 발생하더라도 스스로 복구할 수 있는 것을 의미합니다.
이는 그 다음 설명 <b>트랜스포메이션과 액션</b>과 <b>지연(lazy) 동작과 최적화</b> 부분과 함께 다시 설명드리도록 하겠습니다.

<h4>트랜스포메이션과 액션</h4>
RDD가 제공하는 연산은 크게 트랜스포메이션과 액션이 있습니다. "연산"은 흔히 "메서드"로 이해하시면 됩니다.<br>
트랜스포메이션은 RDD의 변형을 일으키는 연산이고, 실제로 동작이 수행되지는 않습니다. 
<p align='center'><img src='https://imgur.com/wWLMGK1.jpg'><figcaption align='center'>그림 1. RDD 예시</figcaption></p>
<p align='center'><img src='https://imgur.com/ooJKxAu.png'><figcaption align='center'>그림 2.RDD 예시(2)</figcaption></p>

아래 예시를 보면, 데이터를 읽어 RDD를 생성해서 file변수에 저장한 뒤, flatMap -> map -> reduceByKey 함수를 거치면서 RDD[2], RDD[3], RDD[8]을 새로 생성하는 것을 볼 수 있습니다. 이렇게 transformation을 이전 RDD를 변형해서 새로운 RDD를 생성하는 것입니다.

반면에, action은 동작을 수행해서 원하는 타입의 결과를 만들어내는 것이므로, saveAsTextFile로 수행됩니다. 따라서, saveAsTextFile은 action 연산에 해당됩니다. 

<h4>지연 동작과 최적화</h4>
지연 동작이란, 액션 연산이 수행되기 전까지 실제로 트랜스포메이션 연산을 수행하지 않는 것입니다. 이는 RDD의 특성 중 하나인 '회복력'과 관련있습니다. 액션 연산이 수행되기 전까지 동작이 <b>지연</b>이 되는데, 대신에 RDD가 생성되는 방법을 기억하는 것입니다. 따라서 문제가 발생하더라도 기존에 RDD가 생성되는 방법을 기억하여 연산 수행에 문제가 없도록 하는 것입니다. 이는 위의 예시에서 reduceByKey까지는 실제로 트랜스포메이션 연산을 수행하는 것이 아니라 해당 연산을 순서대로 기억해놨다가, saveAsFile연산이 수행될 때(액션 연산이 수행될 때) 비로소 트랜스포메이션 연산도 수행된 것입니다. 

지연 동작 방식의 큰 장점은 <b>실행계획의 최적화</b>입니다. 

<h4>RDD의 불변성</h4>
오류로 인해 스파크의 데이터가 일부 유실되면, 데이터를 다시 만들어내는 방식으로 복구되는 것이 RDD의 불변성입니다. 이는 위에서 계속 언급한 "회복력"과 관련됩니다. 

RDD는 RDD1->RDD2-> ... 가 되면서 한번 만들어진 RDD는 내용이 변경되지 않습니다. RDD를 만드는 방법을 기억해서 문제가 발생 시 언제든지 똑같은 데이터를 생성할 수 있습니다.

<h4>파티션과 HDFS</h4>
- RDD데이터는 클러스터를 구성하는 여러 서버에 나뉘어서 저장됨
- 이 때, 분할된 데이터를 파티션 단위로 관리합니다. 
- HDFS는 하둡의 파일 시스템(hadoop distributed file system)
- 스파크는 하둡 파일 입출력 API에 의존성을 가지고 있음.  

<h4>Job, Executor, 드라이버 프로그램</h4>
- Job : 스파크 프로그램 실행하는 것 = 스파크 잡(job)을 실행하는 것
- 하나의 잡은 클러스터에서 병렬로 처리됨
- 이 때, 클러스터를 구성하는 각 서버마다 executor라는 프로세스가 생성
- 각 executor는 할당된 파티션 데이터를 처리함
- 드라이버란 ? 스파크에서 잡을 실행하는 프로그램으로, 메인함수를 가지고 있는 프로그램
- 드라이버에서 스파크 컨테스트를 생성하고 그 인스턴스를 포함하고 있는 프로그램
- 스파크컨테스트를 생성해 클러스터의 각 워커 노드들에게 작업을 지시하고 결과를 취합하는 역할을 수행

'''Java
public static void main(String[] args) {
    if (ArrayUtils.getLength(args) != 3) {
      System.out.println("Usage: WordCount <Master> <Input> <Output>");
      return;
    }
    // Step1: SparkContext 생성
    JavaSparkContext sc = getSparkContext("WordCount", args[0]);
    try {
      // Step2: 입력 소스로부터 RDD 생성
      JavaRDD<String> inputRDD = getInputRDD(sc, args[1]);
      // Step3: 필요한 처리를 수행
      JavaPairRDD<String, Integer> resultRDD = process(inputRDD);
      // Step4: 수행 결과 처리
      handleResult(resultRDD, args[2]);
    } catch (Exception e) {
      e.printStackTrace();
    } finally {
      // Step5: Spark와의 연결 종료
      sc.stop();
    }
  }'''