<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      TADA, Trend Alignment with Dual-Attention Multi-Task Recurrent Neural Networks for Sales Prediction 논문 리뷰 &middot; Ralasun Resarch Blog
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://raw.githubusercontent.com/ralasun/ralasun.github.io/master/public/favicon.png">
  <link rel="shortcut icon" href="https://raw.githubusercontent.com/ralasun/ralasun.github.io/master/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <img src="http://localhost:4000/public/img/profile_v1.jpg"/>
      </div>
      <div class="sidebar-personal-info-section">
        <p><strong>한걸음씩</strong>, 그리고 <strong>꾸준히</strong> 나아가기</p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me: 
        
        
        
        <a href="https://www.linkedin.com/in/ralasun">
          <i class="fa fa-linkedin" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="https://github.com/ralasun">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:sunhwalsh91@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Posts
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    
  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2021 Seonhwa Lee. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home" title="Ralasun Resarch Blog">
              <img class="masthead-logo" width="200" height="30" src="http://localhost:4000/public/logo.jpg"/>
            </a>
            <small>research blog for data science</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">TADA, Trend Alignment with Dual-Attention Multi-Task Recurrent Neural Networks for Sales Prediction 논문 리뷰</h1>
  <span class="post-date">18 Jan 2021</span>
   | 
  
    <a href="/blog/tags/#time-series-analysis" class="post-tag">time-series-analysis</a>
  
  
  <article>
    <hr />

<p>다변량 시계열 예측 모델에 관한 논문으로, 다변량 시계열 데이터를 가지고 encoder-decoder RNN 모델 기반으로 dual-attention과 multi-task RNN으로 구성된 모델입니다.</p>

<hr />

<h2>Problem</h2>
<p>다변량 시계열 예측을 위한 여러 통계 기반 모델링이 있으나, 판매량에 영향을 주는 변수들 간의 관계를 파악하기 어렵고, 이 변수들로 부터 의미있는 정보(contextual information)을 추출하는 건 더욱 어렵습니다. 예를 들어, 겨울의복은 날씨에 영향에 두드러지게 받지만, 일반적인 셔츠는 사계절내내 잘 입는 옷이기 때문에 겨울의복보단 계절의 영향을 덜 받습니다. 또한 소비자의 주관적인 선호도(브랜드 선호도, 상품 선호도 등)에 따라 상품 판매는 크게 또한 달라지게 됩니다. 따라서, 본 논문에서 주목하는 다변량 시계열 예측에서의 문제는 아래와 같이 크게 세가지입니다.</p>

<ol><li>how to fully capture the dynamic dependencies among multiple influential factors?<br />
판매에 영향을 주는 여러 변수들 간의 관계는 시간에 따라 변할 가능성이 높습니다. 그렇다면 매 스텝마다 변수들 간의 관계를 어떻게 포착할 수 있을까요 ?</li><li>how can we possibly glean wisdoms form the past to compensate for the unpredictability of influential factors?<br />이 변수들이 미래에 어떻게 변할지는 아무도 모릅니다. 그렇다면 과거 이 변수들의 정보만을 가지고 어떻게 미래를 눈여겨 볼 수 있는 정보를 추출할지는 생각해 봐야 합니다.</li>
<li>how to align the upcoming trend with historical sales trends?<br />현실 시계에서의 판매 트랜드는 전혀 규칙적이지 않습니다. 그렇다면 과거 판매 트렌드를 어떻게 하면 현실 트렌드와 연관지을 수 있을까요 ?</li></ol>

<h2>TADA : Trend Alignment with Dual-Attention Multi-Task RNN</h2>

<h3>Problem Formulation</h3>

<p>본 논문에서 풀고자 하는 다변량 시계열 예측 문제는 아래와 같이 수학적으로 정의됩니다.</p>

\[\{\hat{y_t\}}^{T+\triangle}_{t=T+1} = F({\{\mathbf x_t\}}^{T}_{t=1}, {\{y_t\}}^{T}_{t=1})\]

<p>$\mathbf x_t$ 는 influential factors로 판매량 이외의 변수(ex. 날씨, 브랜드, 상품인덱스 등)이고, $y_t$ 는 판매량 입니다.</p>

<h3>TADA 모델 개요</h3>
<p align="center"><img src="https://imgur.com/w09ZSHF.png" /><figcaption align="center">그림 1. 모델 개요</figcaption></p>

<p>위의 그림은 본 논문의 모델 개요입니다. 크게 아래와 같이 구성되어 있습니다.</p>
<ul>
  <li>Multi-task based Encoder Structures</li>
  <li>Dual-Attention based Decoder Structures
    <ul>
      <li>Attention got weighted decoder input mapping</li>
      <li>attention for trend alignment</li>
    </ul>
  </li>
</ul>

<h4>Multi-task based Encoder Structures</h4>
<p align="center"><img src="https://imgur.com/leH0yfV.png" /><figcaption align="center">그림 2. Multi-task based Encoder</figcaption></p>

<p>influential factor의 semantic한 특징을 잘 추출한다면 분명 예측에 도움이 될 것입니다. 그러나 매 타임 스텝마다 어떻게 하면 판매량 예측에 도움될 semantic한 특징을 추출할 수 있을까요 ? 본 논문에서는 influential factor를 크게 intrinsic한 속성과 objective한 속성으로 나누어 LSTM을 이용한 인코딩을 각각 따로하였습니다. 이를 통해 각각 두 개의 LSTM(intrinsic LSTM, external LSTM)을 통해 각기 다른 semantic한 특징을 추출할 수 있습니다. 따라서, 위의 문제 정의는 아래와 같이 다시 정의될 수 있습니다.</p>

\[\{\hat{y_t\}}^{T+\triangle}_{t=T+1} = F({\{\mathbf x_t^{int}\}}^{T}_{t=1}, {\{\mathbf x_t^{ext}\}}^{T}_{t=1}, {\{y_t\}}^{T}_{t=1})\]

<p>intrinsic한 속성이란 브랜드, 카테고리, 가격등 상품과 관련된 것이고, objective한 속성은 날씨, 휴일유무, 할인등과 관련된 속성입니다. 아래 표는 논문에서 실험한 데이터의 intrinsic/objective 속성입니다.</p>

<p>하지만 우리가 구하고 싶은 건 두 가지의 다른 semantic한 feature를 적절하게 결합하여 의미있는 <strong>contextual vector</strong>를 만드는 것입니다. 따라서 또다른 LSTM 네트워크인 Synergic LSTM을 구축하여 joint representation을 학습합니다. 이때, Synergic LSTM에 입력으로 들어가는 건 각 타임스텝에 해당되는 $h_t^{int}$ 와 $h_t^{ext}$ 뿐만 아니라 판매량 $y_t$ 도 같이 joint space가 구축되도록 학습됩니다.</p>

<p>먼저, 두 타입스텝 t에서의 두 개의 hidden state을 $h_t^{int}$ 와 $h_t^{ext}$ 이용하여 Synergic LSTM의 인풋인 $\mathbf X_t^{syn}$ 을 아래와 같이 계산합니다.</p>

\[\mathbf X_t^{syn} = \mathbf W_{syn}[\mathbf h_t^{int};\mathbf h_t^{ext};y_t]\]

<p>그런 다음, intrinsic LSTM/external LSTM과 동일하게 각 타임스텝마다 두 정보가 결합되어 인코딩된 hidden stated인 $\mathbf h^{con}_t$ 를 계산합니다.</p>

<p align="center"><img src="https://imgur.com/ijwajF4.png" /><figcaption align="center">그림 3. Multi-task based Encoder(2)</figcaption></p>

<h4>Dual-Attention based Decoder Structures</h4>
<p>Multi-task Encoder를 통해 과거 판매량 시계열 데이터를 인코딩하면 contextual vectors인 ${\mathbf h_t^{con}}^T_{t=1}$ 이 계산되어 나옵니다. $h_t^{con}$ 은 타임스텝 t까지의 시계열 데이터에 대한 contextual 정보를 품고 있습니다.</p>

<p>LSTM decoder도 encoder와 유사하게 예측에 필요한 contextual vector $\mathbf d_t^{con}$ 을 생성합니다. 따라서, $T &lt; t \leq T + \Delta$ 에 대해 decoder 수학식은 아래와 같습니다.</p>

\[\mathbf d_t^{con} = LSTM^{dec}(\mathbf x_t^{dec}, \mathbf d^{con}_{t-1})\]

<p>위 식에서 $\mathbf x_t^{dec}$ 는 attention weighted input입니다. 그러면 contextual vector가 어떻게 만들어지는지 보기 전에 attention weighted input 계산 과정을 살펴봅시다.</p>

<h5>Attention for Weighted Decoder Input Mapping</h5>

<p align="center"><img src="https://imgur.com/NvCkYMs.png" /><figcaption align="center">그림 4. Attention for Weighted Decoder Input</figcaption></p>

<p>Decoder에 입력될 Input은 encoder contextual vector들에서 각 디코터 타임 스텝에 필요한 정보를 적절하게 취하도록 하기 위해 attention 메카니즘을 통해 생성합니다.</p>

\[\mathbf x_t^{dec} = \mathbf W_{dec}\left[\sum_{t'=1}^T \alpha_{tt'}^{int}\mathbf h_{t'}^{int};\sum_{t'=1}^T \alpha_{tt'}^{ext}\mathbf h_{t'}^{ext}\right] + \mathbf b_{dec}\]

<p>$\alpha_{tt’}^{int}$ 와 $\alpha_{tt’}^{ext}$ 는 어텐션 가중치를 의미합니다. 어텐션 가중치는 아래 과정을 통해 계산됩니다.</p>

\[e^{int}_{tt'} = \mathbf v^{\mathrm T}_{int}tanh(\mathbf M_{int}\mathbf d_{t-1}^{con} + \mathbf H_{int}\mathbf h_{t'}^{int})\]

\[e^{ext}_{tt'} = \mathbf v^{\mathrm T}_{ext}tanh(\mathbf M_{int}\mathbf d_{t-1}^{con} + \mathbf H_{ext}\mathbf h_{t'}^{ext})\]

\[\alpha_{tt'}^{int} = \frac{exp(e_{tt'}^{int})}{\sum_{s=1}^{T}exp(e_{ts}^{int})}\]

\[\alpha_{tt'}^{ext} = \frac{exp(e_{tt'}^{ext})}{\sum_{s=1}^{T}exp(e_{ts}^{ext})}\]

<p>이때, $\sum_{t’=1}^{T}\alpha_{tt’}^{int} = \sum_{t’=1}^{T}\alpha_{tt’}^{ext} = 1$ 이 여야 합니다.</p>

<h5>Attention for Trend Alignment</h5>

<p align="center"><img src="https://imgur.com/riUczJ9.png" /><figcaption align="center">그림 5. Attention for Trend Alignment</figcaption></p>

<p>미래를 예측하기 위해선 과거의 trend 패턴을 안다면 좀 더 수월할 수 있습니다. 따라서, 미래에 예상되는 패턴과 유사한 패턴을 과거에서 찾는 작업을 attention을 통해 진행하는 과정을 본 논문에서 제안하였습니다. 그러나, 
일반적으로 attention 메카니즘은 현 타임스텝에서 아웃풋을 출력하기 위해 이전 hidden state들중에서 가장 align되는 정보를 선택합니다. 과거 정보들 중에서 <strong>미래의 트렌드와 유사한 트렌드 정보</strong>를 선택적으로 이용하고 싶다면 전통적인 attention 메카니즘을 그대로 사용하기는 어렵습니다. 왜냐하면, 일반적인 데이터에선 trend외에 노이즈도 많이 포함하고 있기 때문입니다. 즉, 전체 데이터에 trend + noise라서 이전 모든 과거들에서 유사한 trend 패턴만을 집중하는 건 힘듭니다. 따라서 논문 저자는 아래와 같은 방법을 고안하였습니다.</p>

<p>먼저, ${\mathbf h_t^{con}}_{t=1}^T$ 를 $\triangle$ 타임 스텝 크기에 해당되는  contextual vector를 이어붙여서 $\triangle$ -step trend vector를 생성합니다.</p>

<p align="center"><img src="https://imgur.com/yUmHRP0.png" /></p>

<p>$\mathbf p_i$ 는 과거 시계열 데이터에서 $\triangle$ 간격에 해당되는 구간의 트렌드를 나타냅니다. $i$ 가 1씩 증가하므로, 마치 슬라이딩 윈도우 1씩 움직이면서 트렌드를 포착하는 것과 유사합니다.</p>

<p>마찬가지 방식으로 decoder hidden state들을 이어 붙여 미래에 예상될 트렌드 정보를 생성합니다.</p>

<p align="center"><img src="https://imgur.com/I9C1wnQ.png" /></p>

<p>따라서, 그림5 처럼 과거에 생성된 트렌드 벡터과 미래 트렌드 벡터를 각각 내적하여 가장 큰 값에 해당되는 인덱스 i를 반환합니다. 내적값이 가장 크다는 것은 가장 유사함을 의미합니다.</p>

\[e_i^{trd} = \mathbf p_i^{\mathrm T} \tilde{\mathbf p}\]

\[i' = argmax(e_i^{trd} , e_{i+1}^{trd},\dots, e_{T+\triangle -1}^{trd})\]

<p>그 다음 $\mathbf p_{i’}$ 내의 각 ${\mathbf d_t^{con}}$ 와 $\mathbf h_t^{con}$ 을 아래와 같은 계산과정을 거쳐서 $\tilde {\mathbf d}^{con}$ 을 생성합니다.</p>

<p align="center"><img src="https://imgur.com/haL8Udd.png" /></p>

<p>$\tilde {\mathbf d}^{con}$ 은 타임스텝 t에서의 과거 유사한 트렌드 정보에 집중하여 생성된 aligned contextual vector 입니다.</p>

<h4>Sales Prediction and Model Learning</h4>

<p>위에서 생성된 aligned contextual vector ${\widetilde {\mathbf d_t}^{con}}$ 를 가지고 판매량을 예측합니다.</p>

\[\hat y_t = \mathbf v_y^{\mathrm T} \mathbf {\widetilde d}^{con} + b_y\]

<p>$\hat y_t , \,\,(T+1 \leq t \leq T+\Delta)$ 는 타임스텝 T에서의 예측된 판매량입니다.</p>

<p>본 논문에서 학습은 L2 regularization과 함께 Mean Squared Error를 minimize하였습니다.</p>

<h2>Experiment and result.</h2>

<p>전체적인 결과에 관한 건 논문을 참고 바랍니다. trend alignment 부분에 대한 결과를 살펴보면 과거 유사하다고 찾은 trend와 예측된 trend는 아래 그래프와 같이 나왔습니다.</p>

<p align="center"><img src="https://imgur.com/F5w1W2o.png" /></p>
<p>보면 어느정도 과거 매치된 트렌드와 유사한 트렌드를 따르는 것을 확인할 수 있었습니다.</p>

<h2>Lessons Learned</h2>
<ul>
  <li>결과를 보면 어느정도 lag가 발생하는 것으로 보입니다.</li>
  <li>trend에 대한 파악을 먼저하고 판매량 데이터 입력을 나중에 하면 어떨까?</li>
  <li>dual-stage attention에서의 input attention 모듈과 multi-tasked encoder를 결합하는 건 어떨까 ??</li>
</ul>

<hr />

<p>이상으로 본 논문 리뷰를 마치겠습니다.</p>

<hr />
<ol>
  <li>Chen, Tong, et al. “Tada: trend alignment with dual-attention multi-task recurrent neural networks for sales prediction.” 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 2018.</li>
</ol>

  </article>
</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/signal%20analysis/2021/06/21/stft-dwt/">
            Short-time Fourier Transform(STFT) 과 Discrete Wavelet Transform(DWT)
            <small>21 Jun 2021</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/signal%20analysis/2021/06/18/ft-vs-wt/">
            Discrete Fourier Transform에 대하여
            <small>18 Jun 2021</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/deep%20learning/2021/03/06/gcn(2)/">
            Graph Convolutional Network에 대하여 - Spectral Graph Convolution(2)(작성 중)
            <small>06 Mar 2021</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'http://localhost:4000/deep%20learning/2021/01/18/tada/'; // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = '/deep%20learning/2021/01/18/tada'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = '//ralasun-github-io.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>
    
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-166283746-1', 'auto');
ga('send', 'pageview');
    </script>
    
  </body>
  
  <script id="dsq-count-scr" src="//ralasun-github-io.disqus.com/count.js" async></script>
  
</html>
